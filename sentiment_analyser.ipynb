{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5afd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de32c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\saaim asad\\\\Desktop\\\\roman.csv\\\\sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705c4b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment\n",
       "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive\n",
       "1                                          sahi bt h  Positive\n",
       "2                                        Kya bt hai,  Positive\n",
       "3                                         Wah je wah  Positive\n",
       "4                               Are wha kaya bat hai  Positive"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26df116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d67aec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cce312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095     meri dua hai ke hamari films pehle ki tarha na...\n",
      "3857                                             ji bilkul\n",
      "18461                             allah apko salamat rakhy\n",
      "9962     aurstoo tumen sub ka jawab dena oare ga ek din...\n",
      "19235                             boht tarsawa hai bechara\n",
      "Name: sentence, dtype: object\n",
      "2095     3\n",
      "3857     2\n",
      "18461    3\n",
      "9962     2\n",
      "19235    1\n",
      "Name: sentiment, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\saaim asad\\\\Desktop\\\\roman.csv\\\\sentiment.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Function to clean and preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'sentence' column\n",
    "df_cleaned['sentence'] = df_cleaned['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Encode sentiment labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['sentiment'] = label_encoder.fit_transform(df_cleaned['sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_cleaned['sentence'], df_cleaned['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7959be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6595797280593325\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.64      0.49      0.56      1050\n",
      "     Neutral       0.66      0.76      0.71      1815\n",
      "    Positive       0.67      0.65      0.66      1180\n",
      "\n",
      "    accuracy                           0.66      4045\n",
      "   macro avg       0.66      0.63      0.64      4045\n",
      "weighted avg       0.66      0.66      0.65      4045\n",
      "\n",
      "Unique classes in y_test: {1, 2, 3}\n",
      "Unique classes in y_pred: {1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\saaim asad\\\\Desktop\\\\roman.csv\\\\sentiment.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Function to clean and preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'sentence' column\n",
    "df_cleaned['sentence'] = df_cleaned['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Encode sentiment labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['sentiment'] = label_encoder.fit_transform(df_cleaned['sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_cleaned['sentence'], df_cleaned['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Find the unique classes in y_test and y_pred\n",
    "unique_classes = sorted(set(y_test) | set(y_pred))\n",
    "target_names = [label_encoder.inverse_transform([i])[0] for i in unique_classes]\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, labels=unique_classes, target_names=target_names)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "# Check the unique classes in y_test and y_pred\n",
    "unique_y_test = set(y_test)\n",
    "unique_y_pred = set(y_pred)\n",
    "\n",
    "print(f\"Unique classes in y_test: {unique_y_test}\")\n",
    "print(f\"Unique classes in y_pred: {unique_y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a982715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09e988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
